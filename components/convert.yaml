# Copyright 2022 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     https://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: Convert
description: Converts an LLM to the FasterTransformer optimized version of that model.

inputs:
- {name: "Model Checkpoint", type: String, description: 'Path to the model. This can either be a HuggingFace repository or a GCS bucket link in the format of "gs://<bucket>/<path>"'}
- {name: "GPU DSM", type: String, description: 'DSM of the GPU this model will be deployed to. Reference: https://github.com/NVIDIA/FasterTransformer/blob/main/docs/t5_guide.md#build-the-project'}
- {name: "GPU Number", type: Integer, description: 'Number of GPUs this model will be split across when deployed to.'}
- {name: "Subdirectory", type: String, description: 'Subdirectory model will be uploaded to (appended to "Converted Model" output)'}

outputs:
- {name: Converted Model, type: GCSPath, description: 'Path to converted model in GCS'}

implementation:
  container:
    image: gcr.io/llm-containers/convert
    command: [
      ./all_in_one.sh,
      {inputValue: GPU DSM},
      {inputValue: Model Checkpoint},
      {inputValue: GPU Number},
      {outputValue: Converted Model},
      {inputValue: Subdirectory}
    ]
